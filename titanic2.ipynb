{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#models & metrics\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import plot_importance\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_validate   #Additional scklearn functions\n",
    "from sklearn.model_selection import GridSearchCV   #Perforing grid search\n",
    "\n",
    "\n",
    "#modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4\n",
    "\n",
    "#ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "train_df = pd.read_csv(r'/Users/brodyuehara/Desktop/Titanic Machine Learning Project/train.csv')\n",
    "test_df = pd.read_csv(r'/Users/brodyuehara/Desktop/Titanic Machine Learning Project/test.csv')\n",
    "TestId = test_df['PassengerId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of train: (891, 12)\n",
      "Dimensions of test: (418, 11)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimensions of train: {}\".format(train_df.shape))\n",
    "print(\"Dimensions of test: {}\".format(test_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove outliers\n",
    "#train_df = train_df.drop(Outliers_to_drop, axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join train and test sets\n",
    "#Join to obtain the same number of features during categorical concerison\n",
    "train_idx = len(train_df)\n",
    "df = pd.concat([train_df,test_df], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age             263\n",
       "Cabin          1014\n",
       "Embarked          2\n",
       "Fare              1\n",
       "Name              0\n",
       "Parch             0\n",
       "PassengerId       0\n",
       "Pclass            0\n",
       "Sex               0\n",
       "SibSp             0\n",
       "Survived        418\n",
       "Ticket            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fill empty and NA values with NaN\n",
    "df = df.fillna(np.nan)\n",
    "\n",
    "#check for Null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix between numerical values (SibSp Parch Age and Fare values) and Survived \n",
    "#g = sns.heatmap(train_df[[\"Survived\",\"SibSp\",\"Parch\",\"Age\",\"Fare\"]].corr(),annot=True, fmt = \".2f\", cmap = \"coolwarm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 18 unique titles.\n",
      "\n",
      " ['Mr' 'Mrs' 'Miss' 'Master' 'Don' 'Rev' 'Dr' 'Mme' 'Ms' 'Major' 'Lady'\n",
      " 'Sir' 'Mlle' 'Col' 'Capt' 'the Countess' 'Jonkheer' 'Dona']\n"
     ]
    }
   ],
   "source": [
    "#new feature to extract title names from the Name column\n",
    "df[\"Title\"] = df.Name.apply(lambda name: name.split(',')[1].split('.')[0].strip())\n",
    "\n",
    "#show count of titles\n",
    "print(\"There are {} unique titles.\".format(df.Title.nunique()))\n",
    "\n",
    "#show unique titles\n",
    "print(\"\\n\", df.Title.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr         757\n",
      "Miss       262\n",
      "Mrs        200\n",
      "Master      61\n",
      "Officer     23\n",
      "Royalty      6\n",
      "Name: Title, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#normalize the titles\n",
    "normalized_titles = {\n",
    "    \"Capt\":       \"Officer\",\n",
    "    \"Col\":        \"Officer\",\n",
    "    \"Major\":      \"Officer\",\n",
    "    \"Jonkheer\":   \"Royalty\",\n",
    "    \"Don\":        \"Royalty\",\n",
    "    \"Sir\" :       \"Royalty\",\n",
    "    \"Dr\":         \"Officer\",\n",
    "    \"Rev\":        \"Officer\",\n",
    "    \"the Countess\":\"Royalty\",\n",
    "    \"Dona\":       \"Royalty\",\n",
    "    \"Mme\":        \"Mrs\",\n",
    "    \"Mlle\":       \"Miss\",\n",
    "    \"Ms\":         \"Mrs\",\n",
    "    \"Mr\" :        \"Mr\",\n",
    "    \"Mrs\" :       \"Mrs\",\n",
    "    \"Miss\" :      \"Miss\",\n",
    "    \"Master\" :    \"Master\",\n",
    "    \"Lady\" :      \"Royalty\"\n",
    "}\n",
    "\n",
    "#map normolized titles to the current titles\n",
    "df.Title = df.Title.map(normalized_titles)\n",
    "\n",
    "#view value counts for the normalized titles\n",
    "print(df.Title.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1309 entries, 0 to 1308\n",
      "Data columns (total 13 columns):\n",
      "Age            1309 non-null float64\n",
      "Cabin          295 non-null object\n",
      "Embarked       1307 non-null object\n",
      "Fare           1308 non-null float64\n",
      "Name           1309 non-null object\n",
      "Parch          1309 non-null int64\n",
      "PassengerId    1309 non-null int64\n",
      "Pclass         1309 non-null int64\n",
      "Sex            1309 non-null object\n",
      "SibSp          1309 non-null int64\n",
      "Survived       891 non-null float64\n",
      "Ticket         1309 non-null object\n",
      "Title          1309 non-null object\n",
      "dtypes: float64(3), int64(4), object(6)\n",
      "memory usage: 133.0+ KB\n"
     ]
    }
   ],
   "source": [
    "#apply the grouped median value on null ages\n",
    "df['Age']=df.groupby(['Sex', 'Title', 'Pclass'])['Age'].apply(lambda x: x.fillna(x.median()))\n",
    "\n",
    "#view changes\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract cabin deck \n",
    "deck = {\"A\": 1, \"B\": 2, \"C\": 3, \"D\": 4, \"E\": 5, \"F\": 6, \"G\": 7, \"U\": 8}\n",
    "data = [df]\n",
    "\n",
    "for dataset in data: \n",
    "    dataset['Cabin'] = dataset['Cabin'].fillna(\"U0\")\n",
    "    dataset['Deck'] = dataset['Cabin'].map(lambda x: re.compile(\"([a-zA-Z]+)\").search(x).group())\n",
    "    dataset['Deck'] = dataset['Deck'].map(deck)\n",
    "    dataset['Deck'] = dataset['Deck'].fillna(0)\n",
    "    dataset['Deck'] = dataset['Deck'].astype(int)\n",
    "    \n",
    "#drop cabin feature\n",
    "df = df.drop(['Cabin'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill in two missing females as S according to google\n",
    "df['Embarked'] = df['Embarked'].fillna('S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill NaN with median fare\n",
    "med_fare = df.groupby(['Pclass', 'Parch', \"SibSp\"]).Fare.median()[3][0][0]\n",
    "\n",
    "#fill in missing values in fare with the median fare of 3rd class alone passenger\n",
    "df['Fare'] = df['Fare'].fillna(med_fare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1309 entries, 0 to 1308\n",
      "Data columns (total 13 columns):\n",
      "Age            1309 non-null float64\n",
      "Embarked       1309 non-null object\n",
      "Fare           1309 non-null float64\n",
      "Name           1309 non-null object\n",
      "Parch          1309 non-null int64\n",
      "PassengerId    1309 non-null int64\n",
      "Pclass         1309 non-null int64\n",
      "Sex            1309 non-null object\n",
      "SibSp          1309 non-null int64\n",
      "Survived       891 non-null float64\n",
      "Ticket         1309 non-null object\n",
      "Title          1309 non-null object\n",
      "Deck           1309 non-null int64\n",
      "dtypes: float64(3), int64(5), object(5)\n",
      "memory usage: 133.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#size of families (inluding the passenger)\n",
    "df['FamilySize'] = df.Parch + df.SibSp + 1\n",
    "\n",
    "#new features for familysize\n",
    "df['Single'] = df['FamilySize'].map(lambda x: 1 if x == 1 else 0)\n",
    "df['SmallFamily'] = df['FamilySize'].map(lambda x: 1 if x == 2 else 0)\n",
    "df['MediumFamily'] = df['FamilySize'].map(lambda x: 1 if 3 <= x <= 4 else 0)\n",
    "df['LargeFamily'] = df['FamilySize'].map(lambda x: 1 if x >= 5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fare per person\n",
    "df['Fare_Per_Person'] = df.Fare/(df.SibSp + df.Parch + 1)\n",
    "df['Fare_Per_Person'] = df.Fare_Per_Person.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dummy variables\n",
    "df = pd.get_dummies(df, columns = ['Title'])\n",
    "df = pd.get_dummies(df, columns = ['Embarked'], prefix='Em')\n",
    "df = pd.get_dummies(df, columns = [\"Ticket\"], prefix=\"T\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert sex\n",
    "genders = {\"male\": 0, \"female\": 1}\n",
    "data = [df]\n",
    "\n",
    "for dataset in data:\n",
    "    dataset['Sex'] = dataset['Sex'].map(genders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create categorical values for Pclass\n",
    "df['Pclass'] = df['Pclass'].astype('category')\n",
    "df = pd.get_dummies(df, columns = ['Pclass'],prefix='Pc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop useless variables \n",
    "df.drop(labels = ['PassengerId'], axis = 1, inplace = True)\n",
    "df.drop(labels = ['Name'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[:train_idx]\n",
    "test = df[train_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate train features and label \n",
    "\n",
    "train[\"Survived\"] = train[\"Survived\"].astype(int)\n",
    "\n",
    "y = train[\"Survived\"]\n",
    "\n",
    "X = train.drop(labels = [\"Survived\"],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, val_X, train_y, val_y = train_test_split(X,y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier(booster='gbtree', silent=0, seed=0, base_score=0.5, subsample=0.75)\n",
    "parameters = {'n_estimators':[240,280,320],\n",
    "            'max_depth':[10,11,12],\n",
    "            'gamma':[0,1,2,3],\n",
    "            'max_delta_step':[0,1,2],\n",
    "            'min_child_weight':[1,2,3], \n",
    "            'colsample_bytree':[0.55,0.6,0.65],\n",
    "            'learning_rate':[0.1,0.2,0.3]\n",
    "            }\n",
    "model = GridSearchCV(model, parameters)\n",
    "model.fit(train_X,train_y)\n",
    "print('Best parameters founded : {}'.format(model.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier(booster='gbtree', silent=1, seed=0, base_score=0.5, subsample=0.75)\n",
    "grid ={'max_delta_step': 0, 'max_depth': 10, 'min_child_weight': 2, 'n_estimators': 280, 'colsample_bytree': 0.65, 'gamma': 2}\n",
    "model.set_params(**grid)\n",
    "model.fit(train_X,train_y)\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "results = cross_val_score(model, np.array(val_X), np.array(val_y), cv=kfold)\n",
    "print(\"Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "plot_importance(model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions = model.predict(val_X)\n",
    "print(\"Mean Absolute Error: \"+ str(mean_absolute_error(predictions, val_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission_preds = pd.Series(model.predict(test), name = 'Survived')\n",
    "accuracy = accuracy_score(val_y, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df with predicitons\n",
    "results = pd.concat([TestId, submission_preds], axis=1)\n",
    "results.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to csv\n",
    "results.to_csv(r'C:\\Users\\buehara\\Titanic\\Titanic_kaggle.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the probabilities of predictions\n",
    "y_scores = model.predict_proba(val_X)\n",
    "y_scores = y_scores[:,1]\n",
    "\n",
    "precision, recall, threshold = precision_recall_curve(val_y, y_scores)\n",
    "\n",
    "def plot_precision_and_recall(precision, recall, threshold):\n",
    "    plt.plot(threshold, precision[:-1], \"r-\", label=\"precision\", linewidth=2)\n",
    "    plt.plot(threshold, recall[:-1], \"b\", label=\"recall\", linewidth=2)\n",
    "    plt.xlabel(\"threshold\", fontsize=15)\n",
    "    plt.legend(loc=\"upper right\", fontsize=15)\n",
    "    plt.ylim([0, 1])\n",
    "    \n",
    "plt.figure(figsize=(14, 7))\n",
    "plot_precision_and_recall(precision, recall, threshold)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute true positive rate and false positive rate\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(val_y, y_scores)\n",
    "\n",
    "#plotting them against each other\n",
    "def plot_roc_curve(false_positive_rate, true_positive_rate, label=None):\n",
    "    plt.plot(false_positive_rate, true_positive_rate, linewidth=2, label=label)\n",
    "    plt.plot([0,1], [0,1], 'r', linewidth=2)\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.xlabel('False Positive Rate (FPR)', fontsize=16)\n",
    "    plt.ylabel('True Positive Rate (TPR)', fontsize=16)\n",
    "    \n",
    "plt.figure(figsize=(14, 7))\n",
    "plot_roc_curve(false_positive_rate, true_positive_rate)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROC AUC Score, Score represents the percentage chance theat model will be able to distinguish \n",
    "#between positive class and negative class. \n",
    "r_a_score = roc_auc_score(val_y, y_scores)\n",
    "print(\"ROC-AUC-SCORE:\", r_a_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.DataFrame()\n",
    "features['feature'] = train_X.columns\n",
    "features['importance'] = model.feature_importances_\n",
    "features.sort_values(by=['importance'], ascending=True, inplace=True)\n",
    "features.set_index('feature', inplace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
